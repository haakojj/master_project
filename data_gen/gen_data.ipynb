{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFont, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate font data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text(text, font, render_size, offset):\n",
    "  img = Image.new(\"L\", render_size, 255)\n",
    "  draw = ImageDraw.Draw(img)\n",
    "  draw.text(offset, text, font=font)\n",
    "  return np.asarray(img)\n",
    "\n",
    "def gen_text(text_len, rng=np.random.RandomState(0)):\n",
    "  l = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "  L = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "  n = \"0123456789\"\n",
    "  text = []\n",
    "  while len(text) < text_len:\n",
    "    r = rng.uniform()\n",
    "    if r<0.2:\n",
    "      if rng.uniform()<0.1:\n",
    "        text.append(\"!\")\n",
    "      else:\n",
    "        text.append(\".\")\n",
    "      text.append(\" \")\n",
    "      text.append(L[rng.randint(0, 26)])\n",
    "    elif r<0.25:\n",
    "      text.append(\",\")\n",
    "      text.append(\" \")\n",
    "    elif r<0.255:\n",
    "      text.append(n[rng.randint(0, 10)])\n",
    "    else:\n",
    "      text.append(l[rng.randint(0, 26)])\n",
    "  return \"\".join(text)[:text_len]\n",
    "  \n",
    "txt_map = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 .,!\"  \n",
    "r_txt_map = dict([(k, v) for v, k in enumerate(txt_map)])\n",
    "\n",
    "def gen_sample(text_len, font, render_size, offset, rng):\n",
    "  text = gen_text(text_len, rng)\n",
    "  img = draw_text(text, font, render_size, offset)\n",
    "  img = (1/255)*img.astype(np.float32)\n",
    "  label = np.array([r_txt_map[k] for k in text], dtype=np.uint8)\n",
    "  return img, label\n",
    "\n",
    "def gen_font_list():\n",
    "  font_list_1 = [\n",
    "    \"data/static/DancingScript-Regular.ttf\",\n",
    "    \"data/static/DancingScript-Medium.ttf\",\n",
    "    \"data/static/DancingScript-SemiBold.ttf\",\n",
    "    \"data/static/DancingScript-Bold.ttf\"]\n",
    "  font_list_1 = [[ImageFont.truetype(f, fs) for fs in [23, 24, 25, 26]] for f in font_list_1]\n",
    "  font_list_2 = [ImageFont.truetype(\"data/IndieFlower-Regular.ttf\", fs) for fs in [21, 22, 23, 24]]\n",
    "  font_list = [font_list_1, [font_list_2, font_list_2, font_list_2, font_list_2]]\n",
    "  return font_list\n",
    "\n",
    "font_list = gen_font_list()\n",
    "    \n",
    "def gen_samples(n, k, rng, add_noise=False, text_len = 26, render_size = (256, 32)):  \n",
    "  offset_r = rng.randint(0, 6, (n, 2))\n",
    "  font_r = rng.randint(0, 4, (n, 2))\n",
    "  imgs = np.empty((n, render_size[1], render_size[0]), np.float32)\n",
    "  labels = np.empty((n, text_len), np.uint8)\n",
    "  for i, offset, font_i in zip(range(n), offset_r, font_r):\n",
    "    font = font_list[k][font_i[0]][font_i[1]]\n",
    "    offset = tuple(offset)\n",
    "    img, label = gen_sample(text_len, font, render_size, offset, rng)\n",
    "    imgs[i] = img\n",
    "    labels[i] = label\n",
    "   \n",
    "  if add_noise:\n",
    "    noise = rng.normal(0, 0.1, imgs.shape)\n",
    "    imgs += noise\n",
    "    m = rng.uniform(0, 1, imgs.shape)\n",
    "    imgs[m<0.01] = 0\n",
    "    imgs[m>0.99] = 1\n",
    "  imgs = np.clip(imgs, 0, 1)\n",
    "  imgs = np.expand_dims(imgs, -1)\n",
    "  return imgs, labels\n",
    "\n",
    "def gen_char_samples(n, k, rng, add_noise=False, render_size = (32, 32)):\n",
    "  offset_r = rng.randint(0, 6, (n, 2))\n",
    "  font_r = rng.randint(0, 4, (n, 2))\n",
    "  imgs = np.empty((n, render_size[1], render_size[0]), np.float32)\n",
    "  labels = rng.randint(0, len(txt_map)-4, n).astype(np.uint8)\n",
    "  for i, offset, font_i, label in zip(range(n), offset_r, font_r, labels):\n",
    "    font = font_list[k][font_i[0]][font_i[1]]\n",
    "    offset = tuple(offset)\n",
    "    img = draw_text(txt_map[label], font, render_size, offset)\n",
    "    imgs[i] = (1/255)*img.astype(np.float32)\n",
    "   \n",
    "  if add_noise:\n",
    "    noise = rng.normal(0, 0.1, imgs.shape)\n",
    "    imgs += noise\n",
    "    m = rng.uniform(0, 1, imgs.shape)\n",
    "    imgs[m<0.01] = 0\n",
    "    imgs[m>0.99] = 1\n",
    "  imgs = np.clip(imgs, 0, 1)\n",
    "  imgs = np.expand_dims(imgs, -1)\n",
    "  return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_txt_samples():\n",
    "  n = 10000\n",
    "  rng = np.random.RandomState(0)\n",
    "\n",
    "  imgs_0, labels_0 = gen_samples(n, 0, rng)\n",
    "  imgs_1, labels_1 = gen_samples(n, 1, rng)\n",
    "  np.savez(\"txt_data_nn.npz\", imgs_0=imgs_0, labels_0=labels_0, imgs_1=imgs_1, labels_1=labels_1)\n",
    "\n",
    "  imgs_0, labels_0 = gen_samples(n, 0, rng, True)\n",
    "  imgs_1, labels_1 = gen_samples(n, 1, rng, True)\n",
    "  np.savez(\"txt_data.npz\", imgs_0=imgs_0, labels_0=labels_0, imgs_1=imgs_1, labels_1=labels_1)\n",
    "save_txt_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_char_samples():\n",
    "  n = 10000\n",
    "  rng = np.random.RandomState(0)\n",
    "\n",
    "  imgs_0, labels_0 = gen_char_samples(n, 0, rng)\n",
    "  imgs_1, labels_1 = gen_char_samples(n, 1, rng)\n",
    "  np.savez(\"char_data_nn.npz\", imgs_0=imgs_0, labels_0=labels_0, imgs_1=imgs_1, labels_1=labels_1)\n",
    "\n",
    "  imgs_0, labels_0 = gen_char_samples(n, 0, rng, True)\n",
    "  imgs_1, labels_1 = gen_char_samples(n, 1, rng, True)\n",
    "  np.savez(\"char_data.npz\", imgs_0=imgs_0, labels_0=labels_0, imgs_1=imgs_1, labels_1=labels_1)\n",
    "save_char_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import handwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[584, 635, 548, 671, 567, 551, 634, 588, 552, 0]\n",
      "sentences_0: 693\n",
      "sentences_1: 127\n",
      "max: [1829  116]\n"
     ]
    }
   ],
   "source": [
    "def glob_sentences(form_id):\n",
    "    dir_path = os.path.join(\"data\", form_id.split(\"-\")[0], form_id)\n",
    "    return [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "\n",
    "def import_handwriting():\n",
    "    lines = []\n",
    "    with open(\"data/forms.txt\") as f:\n",
    "        for line in f:\n",
    "            lines.append(line)\n",
    "    lines = lines[16:]\n",
    "    lines = [line.split()[:3] for line in lines]\n",
    "    writers = {}\n",
    "    for line in lines:\n",
    "        k = int(line[1])\n",
    "        if k not in writers:\n",
    "            writers[k] = []\n",
    "        writers[k].append((line[0], int(line[2])))\n",
    "\n",
    "    writer_len = []\n",
    "    for k, v in writers.items():\n",
    "        writer_len.append((sum([i[1] for i in v]), k))\n",
    "    writer_len.sort()\n",
    "\n",
    "    sel_w = [w[1] for w in writer_len[-10:]]\n",
    "    print(sel_w)\n",
    "    sel_w = dict([(i, [f[0] for f in writers[i]]) for i in sel_w])\n",
    "    \n",
    "    # chosen writers: 0, 552\n",
    "    f0 = sel_w[0]\n",
    "    f1 = sel_w[552]\n",
    "    \n",
    "    sentences_0 = []\n",
    "    for f in f0:\n",
    "        sentences_0.extend(glob_sentences(f))\n",
    "    sentences_1 = []\n",
    "    for f in f1:\n",
    "        sentences_1.extend(glob_sentences(f))\n",
    "    print(f\"sentences_0: {len(sentences_0)}\")\n",
    "    print(f\"sentences_1: {len(sentences_1)}\")\n",
    "\n",
    "    sizes = []\n",
    "    for p in sentences_1:\n",
    "        img = Image.open(p)\n",
    "        sizes.append(img.size)\n",
    "    sizes = np.array(sizes)\n",
    "    print(f\"max: {sizes.max(0)}\")\n",
    "    \n",
    "    imgs_1 = np.full((127, 116, 1829), 255, np.uint8)\n",
    "    for i, p in enumerate(sentences_1):\n",
    "        img = Image.open(p)\n",
    "        s = img.size\n",
    "        imgs_1[i, :s[1], :s[0]] = np.array(img)\n",
    "    imgs_1 = (1/255)*imgs_1.astype(np.float32)\n",
    "    \n",
    "    imgs_0 = np.full(imgs_1.shape, 255, np.uint8)\n",
    "    c = 0\n",
    "    for p in sentences_0:\n",
    "        img = Image.open(p)\n",
    "        s = img.size\n",
    "        if (s[1] <= imgs_0.shape[1]) and (s[0] <= imgs_0.shape[2]):\n",
    "            imgs_0[c, :s[1], :s[0]] = np.array(img)\n",
    "            c += 1\n",
    "        if c == len(imgs_0):\n",
    "            break\n",
    "    imgs_0 = (1/255)*imgs_0.astype(np.float32)\n",
    "    np.savez(\"wr_data.npz\", imgs_0=imgs_0, imgs_1=imgs_1)\n",
    "import_handwriting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_signatures():\n",
    "    root = \"data/sample_signature/sample_Signature\"\n",
    "    #choosen writers: 1, 3\n",
    "    f1, f3 = [], []\n",
    "    \n",
    "    for f in os.listdir(os.path.join(root, \"genuine\")):\n",
    "        i = int(f[4:7])\n",
    "        p = os.path.join(root, \"genuine\", f)\n",
    "        if i == 1:\n",
    "            f1.append(p)\n",
    "        elif i == 3:\n",
    "            f3.append(p)\n",
    "\n",
    "    f3_1 = []\n",
    "    for f in os.listdir(os.path.join(root, \"forged\")):\n",
    "        i = int(f[4:7])\n",
    "        j = int(f[9:12])\n",
    "        p = os.path.join(root, \"forged\", f)\n",
    "        if i == 3 and j == 1:\n",
    "            f3_1.append(p)\n",
    "\n",
    "    train_x = np.full((len(f1), 800, 1600), 255)\n",
    "    for i in range(len(f1)):\n",
    "        a = np.array(Image.open(f1[i]))\n",
    "        train_x[i, :a.shape[0], :a.shape[1]] = a\n",
    "    train_x = np.expand_dims((1/255)*train_x.astype(np.float32), -1)\n",
    "        \n",
    "    train_y = np.full((len(f3), 800, 1600), 255)\n",
    "    for i in range(len(f3)):\n",
    "        a = np.array(Image.open(f3[i]))\n",
    "        train_y[i, :a.shape[0], :a.shape[1]] = a\n",
    "    train_y = np.expand_dims((1/255)*train_y.astype(np.float32), -1)\n",
    "    \n",
    "    test_x = np.full((len(f3_1), 800, 1600), 255)\n",
    "    for i in range(len(f3_1)):\n",
    "        a = np.array(Image.open(f3_1[i]))\n",
    "        test_x[i, :a.shape[0], :a.shape[1]] = a\n",
    "    test_x = np.expand_dims((1/255)*test_x.astype(np.float32), -1)\n",
    "    \n",
    "    np.savez(\"sig_data.npz\", train_x=train_x, train_y=train_y, test_x=test_x)\n",
    "import_signatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
